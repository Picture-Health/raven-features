{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553a8d9b",
   "metadata": {},
   "source": [
    "# üî¨ Featurization Pipeline Tutorial\n",
    "Using ClearML and Raven to Dynamically Launch Per-Series Jobs\n",
    "üïí *Generated on 2025-07-17*\n",
    "\n",
    "This notebook walks through configuring, launching, and monitoring a modular featurization pipeline using ClearML, Raven, and an internal CLI tool.\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Learn:\n",
    "- How to define a multi-step pipeline using a YAML config\n",
    "- Where to store configs in S3 for remote triggering\n",
    "- How to run the pipeline using the `featurize` CLI\n",
    "- How each step is tracked in ClearML and how logs are preserved\n",
    "\n",
    "### Requirements:\n",
    "- Your AWS credentials configured locally (or just access to the S3 interface)\n",
    "- ClearML configured locally\n",
    "- Installed CLI: \n",
    "    - clone https://github.com/Picture-Health/raven-features\n",
    "    - run `pip install .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087c3e0",
   "metadata": {},
   "source": [
    "## 1 ‚Äì Define Your Pipeline in YAML\n",
    "\n",
    "This YAML config defines everything the pipeline needs to run:\n",
    "- `project_parameters`: general identifiers and owner info\n",
    "- `autoscaler_parameters`: tells the launcher which queue to use\n",
    "- `raven_query_parameters`: defines what to fetch from Raven\n",
    "- `pipeline_steps`: ordered steps, each running in its own repo and queue\n",
    "\n",
    "Each step includes:\n",
    "- `repo`, `branch`, and `commit` to specify the code to run\n",
    "- `script` to execute\n",
    "- `execution_queue` for ClearML\n",
    "- `parent_steps` to enforce dependency order\n",
    "- `output_path` (optional) to control folder structure"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f45cce6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# my-pipeline.yaml\n",
    "\n",
    "project_parameters:\n",
    "  email: amogh@picturehealth.com\n",
    "  project_id: ENG-TESTS\n",
    "  feature_group_id: KOO_SCLC_02_UPSERT_TEST_3\n",
    "\n",
    "autoscaler_parameters:\n",
    "  launcher_queue: PxPipeline_Launcher\n",
    "\n",
    "raven_query_parameters:\n",
    "  modality: radiology\n",
    "  dataset_id: KOO-SCLC-02\n",
    "  organ_mask_type: LUNG\n",
    "  organ_mask_provenance: RAVEN-NIFTI\n",
    "  lesion_mask_type: LUNG-LESIONS\n",
    "  lesion_mask_provenance: RAVEN-ANGO\n",
    "\n",
    "pipeline_steps:\n",
    "  - name: Data Provisioning\n",
    "    repo: https://github.com/Picture-Health/px-data-provision.git\n",
    "    branch: ref/config-standardization\n",
    "    working_directory: .\n",
    "    commit: 15a998d\n",
    "    script: pipeline_entrypoint.py\n",
    "    output_path: provisioned-data\n",
    "    execution_queue: BatchSetup\n",
    "    parent_steps: []\n",
    "    time_limit: 1800\n",
    "\n",
    "  - name: Lesion Splitting\n",
    "    repo: https://github.com/Picture-Health/px-lesion-splitting.git\n",
    "    branch: ref/config-standardization\n",
    "    working_directory: .\n",
    "    commit: 582c1c1\n",
    "    script: pipeline_entrypoint.py\n",
    "    output_path: generated-data\n",
    "    execution_queue: Segmentator\n",
    "    parent_steps: ['Data Provisioning']\n",
    "    time_limit: 1800\n",
    "\n",
    "  - name: Texture Feature Extraction\n",
    "    repo: https://github.com/Picture-Health/pyradiomics.git\n",
    "    branch: ref/config-standardization\n",
    "    working_directory: .\n",
    "    commit: 13df8b5\n",
    "    script: pipeline_entrypoint.py\n",
    "    output_path: features\n",
    "    execution_queue: ML_CPU_compute\n",
    "    parent_steps: ['Lesion Splitting']\n",
    "    time_limit: 36000\n",
    "\n",
    "  - name: QVT Feature Extraction\n",
    "    repo: https://github.com/Picture-Health/vessel-analysis-pipeline.git\n",
    "    branch: ref/config-standardization\n",
    "    working_directory: .\n",
    "    commit: 75ac176\n",
    "    script: pipeline_entrypoint.py\n",
    "    output_path: features\n",
    "    execution_queue: ML_GPU_compute\n",
    "    parent_steps: ['Lesion Splitting']\n",
    "    time_limit: 18000\n",
    "\n",
    "  - name: Upsert Feature Group\n",
    "    repo: https://github.com/Picture-Health/px-upsert-feature-group.git\n",
    "    branch: ref/config-standardization\n",
    "    working_directory: .\n",
    "    commit: 768131c\n",
    "    script: pipeline_entrypoint.py\n",
    "    execution_queue: BatchSetup\n",
    "    parent_steps: ['Texture Feature Extraction', 'QVT Feature Extraction']\n",
    "    time_limit: 1800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c3415",
   "metadata": {},
   "source": [
    "## 2 ‚Äì Upload Your Config to S3\n",
    "\n",
    "The pipeline launcher pulls config files from S3. This cell uploads your YAML to a known location. Note that it is not _required_ that you keep the config in `s3://px-app-bucket/config`, but we advise it for organization's sake.\n",
    "\n",
    "üîÅ You can re-run this cell anytime you make edits to `my_pipeline.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3331a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bucket = \"px-app-bucket\"\n",
    "key = \"config/my-pipeline.yaml\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\"my_pipeline.yaml\", bucket, key)\n",
    "\n",
    "print(f\"‚úÖ Uploaded to s3://{bucket}/{key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c9fe1",
   "metadata": {},
   "source": [
    "## 3 ‚Äì Trigger the Pipeline from CLI\n",
    "\n",
    "Once the config is uploaded, launch your pipeline with the CLI:\n",
    "\n",
    "```bash\n",
    "featurize --config-uri s3://px-app-bucket/config/my_pipeline.yaml\n",
    "```\n",
    "\n",
    "This will:\n",
    "- Query Raven for matching studies\n",
    "- Launch a ClearML pipeline per series\n",
    "- Dynamically execute each pipeline step in order, per ClearML queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642b4c3",
   "metadata": {},
   "source": [
    "## 4 ‚Äì Navigating Results in ClearML\n",
    "\n",
    "Once launched, your pipeline will leave two primary trails in ClearML:\n",
    "\n",
    "---\n",
    "### 1. Launcher Task (YAML Tracker)\n",
    "\n",
    "- **Location**:  \n",
    "  `ClearML UI ‚Üí Projects ‚Üí RAVEN-FEATURES ‚Üí Featurization - {config_name} @ Month DD, YYYY at HH:MM [AM|PM] EDT`\n",
    "\n",
    "- **Purpose**:  \n",
    "  This task logs the config used for pipeline execution.\n",
    "\n",
    "- **Artifacts**:\n",
    "  - The full `my_pipeline.yaml` used to trigger the run\n",
    "  - A list of all series selected by the Raven query\n",
    "  - Status logs for each submitted pipeline run\n",
    "\n",
    "<img src=\"images/pipeline_launcher_yaml_artifact.png\" alt=\"YAML Artifact\" width=\"700\"/>\n",
    "<img src=\"images/pipeline_launcher_logs.png\" alt=\"Launcher Logs\" width=\"700\"/>\n",
    "\n",
    "\n",
    "### 2. Pipeline Runs (Actual Executions)\n",
    "\n",
    "- **Location**:  \n",
    "  `ClearML UI ‚Üí Pipelines ‚Üí RAVEN-FEATURES ‚Üí {project_id} ‚Üí {config_name}-YYYY-MM-DD__HH-MM-SS/`\n",
    "\n",
    "- **Contents**:  \n",
    "  Each directory represents a full run of your per-series pipeline:\n",
    "  - Steps are visualized as a **ClearML DAG**\n",
    "  - Logs and artifacts are stored per step\n",
    "  - Failed steps are clearly marked for debugging\n",
    "\n",
    "- **Tip**: You can click into each step to inspect:\n",
    "  - Input parameters\n",
    "  - Downloadable artifacts (e.g., features, masks, logs)\n",
    "  - Worker queue used\n",
    "  - Execution time and resource usage\n",
    "\n",
    "\n",
    "<img src=\"images/pipeline.png\" alt=\"Pipeline Execution\" width=\"700\"/>\n",
    "\n",
    "\n",
    "Use these views to:\n",
    "- Track your config lineage\n",
    "- Audit all runs from a given config\n",
    "- Debug or rerun failed steps individually"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
